{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Performance Machine Learning Analysis\n",
    "This notebook implements a supervised machine learning solution to predict student performance based on various academic and personal factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING AND EXPLORING THE DATASET\n",
      "============================================================\n",
      "Dataset shape: (10000, 6)\n",
      "Number of samples: 10000\n",
      "Number of features: 6\n",
      "\n",
      "Dataset columns:\n",
      "['Hours Studied', 'Previous Scores', 'Extracurricular Activities', 'Sleep Hours', 'Sample Question Papers Practiced', 'Performance Index']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOADING AND EXPLORING THE DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/StudentPerformance.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")\n",
    "\n",
    "print(\"\\nDataset columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   Hours Studied  Previous Scores Extracurricular Activities  Sleep Hours  \\\n",
      "0              7               99                        Yes            9   \n",
      "1              4               82                         No            4   \n",
      "2              8               51                        Yes            7   \n",
      "3              5               52                        Yes            5   \n",
      "4              7               75                         No            8   \n",
      "\n",
      "   Sample Question Papers Practiced  Performance Index  \n",
      "0                                 1               91.0  \n",
      "1                                 2               65.0  \n",
      "2                                 2               45.0  \n",
      "3                                 2               36.0  \n",
      "4                                 5               66.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Hours Studied                     10000 non-null  int64  \n",
      " 1   Previous Scores                   10000 non-null  int64  \n",
      " 2   Extracurricular Activities        10000 non-null  object \n",
      " 3   Sleep Hours                       10000 non-null  int64  \n",
      " 4   Sample Question Papers Practiced  10000 non-null  int64  \n",
      " 5   Performance Index                 10000 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 468.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics:\n",
      "       Hours Studied  Previous Scores   Sleep Hours  \\\n",
      "count   10000.000000     10000.000000  10000.000000   \n",
      "mean        4.992900        69.445700      6.530600   \n",
      "std         2.589309        17.343152      1.695863   \n",
      "min         1.000000        40.000000      4.000000   \n",
      "25%         3.000000        54.000000      5.000000   \n",
      "50%         5.000000        69.000000      7.000000   \n",
      "75%         7.000000        85.000000      8.000000   \n",
      "max         9.000000        99.000000      9.000000   \n",
      "\n",
      "       Sample Question Papers Practiced  Performance Index  \n",
      "count                      10000.000000       10000.000000  \n",
      "mean                           4.583300          55.224800  \n",
      "std                            2.867348          19.212558  \n",
      "min                            0.000000          10.000000  \n",
      "25%                            2.000000          40.000000  \n",
      "50%                            5.000000          55.000000  \n",
      "75%                            7.000000          71.000000  \n",
      "max                            9.000000         100.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Basic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Hours Studied                       0\n",
      "Previous Scores                     0\n",
      "Extracurricular Activities          0\n",
      "Sleep Hours                         0\n",
      "Sample Question Papers Practiced    0\n",
      "Performance Index                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "Encoded 'Extracurricular Activities': Yes=1, No=0\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy to avoid modifying original data\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "le = LabelEncoder()\n",
    "df_processed['Extracurricular Activities'] = le.fit_transform(df_processed['Extracurricular Activities'])\n",
    "\n",
    "print(\"Encoded 'Extracurricular Activities': Yes=1, No=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance categories distribution:\n",
      "Performance_Category\n",
      "Medium    4933\n",
      "Low       2562\n",
      "High      2505\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create performance categories based on Performance Index\n",
    "performance_bins = [0, 40, 70, 100]\n",
    "performance_labels = ['Low', 'Medium', 'High']\n",
    "df_processed['Performance_Category'] = pd.cut(df_processed['Performance Index'], \n",
    "                                             bins=performance_bins, \n",
    "                                             labels=performance_labels)\n",
    "\n",
    "print(f\"Performance categories distribution:\")\n",
    "print(df_processed['Performance_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (10000, 5)\n",
      "Target shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "feature_columns = ['Hours Studied', 'Previous Scores', 'Extracurricular Activities', \n",
    "                  'Sleep Hours', 'Sample Question Papers Practiced']\n",
    "\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['Performance_Category']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SPLITTING THE DATASET\n",
      "============================================================\n",
      "Training set size: 8000 samples\n",
      "Testing set size: 2000 samples\n",
      "Training set percentage: 80.0%\n",
      "Testing set percentage: 20.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SPLITTING THE DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Training set percentage: {X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]) * 100:.1f}%\")\n",
    "print(f\"Testing set percentage: {X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment 1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 1: RANDOM FOREST CLASSIFIER\n",
      "============================================================\n",
      "Random Forest Accuracy: 0.9405 (94.05%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1: RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.96      0.92      0.94       501\n",
      "         Low       0.94      0.95      0.94       512\n",
      "      Medium       0.93      0.95      0.94       987\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[461   0  40]\n",
      " [  0 484  28]\n",
      " [ 18  33 936]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "                            feature  importance\n",
      "1                   Previous Scores    0.745916\n",
      "0                     Hours Studied    0.171311\n",
      "4  Sample Question Papers Practiced    0.042064\n",
      "3                       Sleep Hours    0.030321\n",
      "2        Extracurricular Activities    0.010388\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_names = ['Hours Studied', 'Previous Scores', 'Extracurricular Activities', \n",
    "                'Sleep Hours', 'Sample Question Papers Practiced']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experiment 2: K-Nearest Neighbors with Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 2: K-NEAREST NEIGHBORS WITH FEATURE SCALING\n",
      "============================================================\n",
      "Applied StandardScaler to normalize features\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2: K-NEAREST NEIGHBORS WITH FEATURE SCALING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Apply feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Applied StandardScaler to normalize features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different k values:\n",
      "k=3: Accuracy = 0.9135 (91.35%)\n",
      "k=5: Accuracy = 0.9145 (91.45%)\n",
      "k=7: Accuracy = 0.9115 (91.15%)\n",
      "k=9: Accuracy = 0.9155 (91.55%)\n",
      "k=11: Accuracy = 0.9210 (92.10%)\n",
      "\n",
      "Best k value: 11 with accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "# Test different k values\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "best_k = 5\n",
    "best_accuracy = 0\n",
    "\n",
    "print(\"Testing different k values:\")\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    y_pred_temp = knn_model.predict(X_test_scaled)\n",
    "    accuracy_temp = accuracy_score(y_test, y_pred_temp)\n",
    "    print(f\"k={k}: Accuracy = {accuracy_temp:.4f} ({accuracy_temp*100:.2f}%)\")\n",
    "    \n",
    "    if accuracy_temp > best_accuracy:\n",
    "        best_accuracy = accuracy_temp\n",
    "        best_k = k\n",
    "\n",
    "print(f\"\\nBest k value: {best_k} with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final KNN Accuracy: 0.9210 (92.10%)\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Final KNN Accuracy: {accuracy_knn:.4f} ({accuracy_knn*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.93      0.91      0.92       501\n",
      "         Low       0.93      0.91      0.92       512\n",
      "      Medium       0.91      0.93      0.92       987\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.92      0.92      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[455   0  46]\n",
      " [  0 467  45]\n",
      " [ 32  35 920]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL COMPARISON AND ANALYSIS\n",
      "============================================================\n",
      "Random Forest Accuracy: 0.9405 (94.05%)\n",
      "KNN Accuracy: 0.9210 (92.10%)\n",
      "\n",
      "Random Forest performs better by 1.95 percentage points\n",
      "Best performing model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON AND ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\")\n",
    "print(f\"KNN Accuracy: {accuracy_knn:.4f} ({accuracy_knn*100:.2f}%)\")\n",
    "\n",
    "if accuracy_rf > accuracy_knn:\n",
    "    print(f\"\\nRandom Forest performs better by {(accuracy_rf - accuracy_knn)*100:.2f} percentage points\")\n",
    "    best_model = \"Random Forest\"\n",
    "elif accuracy_knn > accuracy_rf:\n",
    "    print(f\"\\nKNN performs better by {(accuracy_knn - accuracy_rf)*100:.2f} percentage points\")\n",
    "    best_model = \"KNN\"\n",
    "else:\n",
    "    print(\"\\nBoth models have the same accuracy\")\n",
    "    best_model = \"Tie\"\n",
    "\n",
    "print(f\"Best performing model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "✓ Successfully loaded and explored the student performance dataset\n",
      "✓ Preprocessed data and created performance categories\n",
      "✓ Split data into 80% training and 20% testing sets\n",
      "✓ Conducted Experiment 1: Random Forest Classifier\n",
      "✓ Conducted Experiment 2: KNN with Feature Scaling and Hyperparameter Tuning\n",
      "✓ Evaluated both models using accuracy metric\n",
      "✓ Compared model performances\n",
      "\n",
      "Final Results:\n",
      "- Random Forest Accuracy: 94.05%\n",
      "- KNN Accuracy: 92.10%\n",
      "- Best Model: Random Forest\n",
      "\n",
      "This analysis demonstrates the complete supervised machine learning workflow\n",
      "for predicting student performance based on study habits and personal factors.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✓ Successfully loaded and explored the student performance dataset\")\n",
    "print(\"✓ Preprocessed data and created performance categories\")\n",
    "print(\"✓ Split data into 80% training and 20% testing sets\")\n",
    "print(\"✓ Conducted Experiment 1: Random Forest Classifier\")\n",
    "print(\"✓ Conducted Experiment 2: KNN with Feature Scaling and Hyperparameter Tuning\")\n",
    "print(\"✓ Evaluated both models using accuracy metric\")\n",
    "print(\"✓ Compared model performances\")\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"- Random Forest Accuracy: {accuracy_rf*100:.2f}%\")\n",
    "print(f\"- KNN Accuracy: {accuracy_knn*100:.2f}%\")\n",
    "print(f\"- Best Model: {best_model}\")\n",
    "\n",
    "print(\"\\nThis analysis demonstrates the complete supervised machine learning workflow\")\n",
    "print(\"for predicting student performance based on study habits and personal factors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
